{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad9bbcd-96a4-448b-ab17-ee5d917ac9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb2fa02f-4a6a-44e3-99a8-1866c4919cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ndjson in /opt/conda/lib/python3.10/site-packages (0.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ndjson\n",
    "\n",
    "MY_NAME = \"this is a demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d38370d-ce5c-4422-bbfc-d58cbdd91c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# [START aiplatform_predict_text_classification_single_label_sample]\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "def predict_text_classification_single_label_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    content: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    instance = predict.instance.TextClassificationPredictionInstance(\n",
    "        content=content,\n",
    "    ).to_value()\n",
    "    instances = [instance]\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))\n",
    "\n",
    "\n",
    "# [END aiplatform_predict_text_classification_single_label_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0095189-0287-4ca2-904a-38eaa2e0affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 586862132302184448\n",
      " prediction: {'confidences': [0.9111160635948181, 0.08888395130634308], 'displayNames': ['1', '0'], 'ids': ['8440755603122421760', '3829069584695033856']}\n"
     ]
    }
   ],
   "source": [
    "predict_text_classification_single_label_sample(\n",
    "    project=\"993237196953\",\n",
    "    endpoint_id=\"5449289578420633600\",\n",
    "    location=\"us-central1\",\n",
    "    content=\"@noavggirlhere Oh really?  So you condemn all the right wingers who said the Paul Pelosi attack was just a “lover’s quarrel” right?  You see I know that you know how to use kind words, but I also know that right wingers will justify evil when it suits them.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca19476f-0d0d-4546-bd78-eeb7eeb82216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training1emakia\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"training1emakia\"  # @param {type:\"string\"}\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "166e6fcb-1770-4706-b6ed-07544da1cb07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucile_batch_prediction1\n",
      "gs://lucile_batch_prediction1\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = f\"{MY_NAME}_batch_prediction1\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "print(BUCKET_NAME)\n",
    "print(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed85385-b261-4987-8c1a-d86e8a509fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://lucile_batch_prediction1/...\n"
     ]
    }
   ],
   "source": [
    "#create the bucket \n",
    "!gsutil mb -b on -l us-central1 gs://{MY_NAME}_batch_prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "968b04cd-dde7-43d3-9064-22e966eaf49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import jsonlines\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "client = bigquery.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5a106d1-ecf8-4508-8e65-aa3800024b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text'], dtype='object')\n",
      "@BradleyCullina3 @SenErikaGeiss @GovWhitmer Many agencies do have restrictions on foot and vehicle chases… but there’s a balance between choosing not to chase for risks, and letting everyone avoid legal accountability if they simply flee from officers.\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "FOLDER_NAME= f\"output\"\n",
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "for blob in client.list_blobs(BUCKET_NAME, prefix=FOLDER_NAME):\n",
    "  print(str(blob))\n",
    "\n",
    "input_file_name = \"prediction-input.jsonl\"\n",
    "\n",
    "#gcs_source = 'gs://prediction-data-english/batchpredictioncsv.csv'\n",
    "gcs_source = f'gs://{MY_NAME}_batch_prediction1/dataforbatchprediction_csv.csv' \n",
    "data = pd.read_csv(\n",
    "    gcs_source,      # relative python path to subdirectory\n",
    "    sep=',',           # Tab-separated value file.\n",
    "    #quotechar=\"'\",        # single quote allowed as quote character\n",
    "    usecols=['text']  # Only load the three columns specified.\n",
    "    #na_values=['.', '??']       # Take any '.' or '??' values as NA\n",
    ")\n",
    "print(data.keys())\n",
    "print(data.text[0])\n",
    "#print(data[1])\n",
    "\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "# Iterate over the prediction instances, creating a new TXT file\n",
    "# for each.\n",
    "input_file_data = []\n",
    "for count, t in enumerate(data.text):\n",
    "    instance_name = f\"input_{count}.txt\"\n",
    "    instance_file_uri = f\"{BUCKET_URI}/{instance_name}\"\n",
    "    # Add the data to store in the JSONL input file.\n",
    "    tmp_data = {\"content\": instance_file_uri, \"mimeType\": \"text/plain\"}\n",
    "    input_file_data.append(tmp_data)\n",
    "\n",
    "    # Create the new instance file\n",
    "    blob = bucket.blob(instance_name)\n",
    "    blob.upload_from_string(t)\n",
    "\n",
    "input_str = \"\\n\".join([str(d) for d in input_file_data])\n",
    "file_blob = bucket.blob(f\"{input_file_name}\")\n",
    "file_blob.upload_from_string(input_str)\n",
    "print(\"hello\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ade999-20a1-40e7-9cd2-bc5e966a46f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
