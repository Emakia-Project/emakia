{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad9bbcd-96a4-448b-ab17-ee5d917ac9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../config.py')\n",
    "from config import YOUR_NAME\n",
    "\n",
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d38370d-ce5c-4422-bbfc-d58cbdd91c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "def predict_text_classification_single_label_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    content: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    instance = predict.instance.TextClassificationPredictionInstance(\n",
    "        content=content,\n",
    "    ).to_value()\n",
    "    instances = [instance]\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "\n",
    "    predictions = response.predictions\n",
    "    return dict(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19476f-0d0d-4546-bd78-eeb7eeb82216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"training1emakia\"  # @param {type:\"string\"}\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e6fcb-1770-4706-b6ed-07544da1cb07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = f\"{YOUR_NAME}_batch_prediction\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "print(BUCKET_NAME)\n",
    "print(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968b04cd-dde7-43d3-9064-22e966eaf49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import jsonlines\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "client = bigquery.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a106d1-ecf8-4508-8e65-aa3800024b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER_NAME= f\"output\"\n",
    "from google.cloud import storage\n",
    "from itertools import islice\n",
    "client = storage.Client()\n",
    "\n",
    "input_file_name = f'{YOUR_NAME}_all_prediction.jsonl'\n",
    "\n",
    "#gcs_source = 'gs://prediction-data-english/batchpredictioncsv.csv'\n",
    "gcs_source = f'gs://{YOUR_NAME}_batch_prediction/dataforbatchprediction_csv.csv' \n",
    "data = pd.read_csv(\n",
    "    gcs_source,      # relative python path to subdirectory\n",
    "    sep=',',           # Tab-separated value file.\n",
    "    #quotechar=\"'\",        # single quote allowed as quote character\n",
    "    usecols=['id', 'text']  # Only load the three columns specified.\n",
    "    #na_values=['.', '??']       # Take any '.' or '??' values as NA\n",
    ")\n",
    "\n",
    "\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "# Iterate over the prediction instances, creating a new TXT file\n",
    "# for each.\n",
    "input_file_data = []\n",
    "for count, row in data.iterrows():\n",
    "    response = predict_text_classification_single_label_sample(\n",
    "        project=\"12807912884\",\n",
    "        endpoint_id=\"8493069816616189952\",\n",
    "        location=\"us-central1\",\n",
    "        content=row[\"text\"])\n",
    "    instance_name = f\"input_{count}.txt\"\n",
    "    instance_file_uri = f\"{BUCKET_URI}/{instance_name}\"\n",
    "    # Add the data to store in the JSONL input file.\n",
    "    tmp_data = {\"instance\": {\"content\": instance_file_uri, \"mimeType\": \"text/plain\"},\n",
    "               \"prediction\": response,\n",
    "               \"id\": row[\"id\"],\n",
    "               \"tweet content\": row[\"text\"]}\n",
    "    input_file_data.append(tmp_data)\n",
    "\n",
    "from proto.marshal.collections.repeated import RepeatedComposite\n",
    "    \n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        match o:\n",
    "            case RepeatedComposite():\n",
    "                return list(o)\n",
    "            case _:\n",
    "                return super().default(o)\n",
    "\n",
    "input_str = \"\\n\".join(json.dumps(d, cls=CustomEncoder, ensure_ascii=False) for d in input_file_data)\n",
    "file_blob = bucket.blob(f\"{input_file_name}\")\n",
    "file_blob.upload_from_string(input_str)\n",
    "print(\"jsonl file is created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ade999-20a1-40e7-9cd2-bc5e966a46f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(\"aisdnfiasdnfiowf\")\n",
    "list([1,2,4,2,3,4])\n",
    "list({\"a\", \"b\"})\n",
    "list({\"a\": 1, \"b\": 2})\n",
    "\n",
    "for i in \"aisdnfiasdnfiowf\":\n",
    "    print(i)\n",
    "    \n",
    "it = \"aisdnfiasdnfiowf\".__iter__()\n",
    "try:\n",
    "    while True:\n",
    "        i = it.__next__()\n",
    "        print(i)\n",
    "except StopIteration:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2c2cc-afca-4c07-8a4d-e0f2c9e540fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fbd1d-3e12-4052-9db4-c99ae1b703a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
